{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3911da83",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Packages\" data-toc-modified-id=\"Packages-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Packages</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Classification\" data-toc-modified-id=\"Classification-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Classification</a></span></li><li><span><a href=\"#Regression\" data-toc-modified-id=\"Regression-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Regression</a></span></li><li><span><a href=\"#Bayesian-loss\" data-toc-modified-id=\"Bayesian-loss-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Bayesian loss</a></span></li></ul></li><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data</a></span></li><li><span><a href=\"#Grid-Search\" data-toc-modified-id=\"Grid-Search-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Grid Search</a></span></li><li><span><a href=\"#Bayesian-optimization\" data-toc-modified-id=\"Bayesian-optimization-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Bayesian optimization</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb95e967",
   "metadata": {},
   "source": [
    "___\n",
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8298c767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 16:51:47.494329: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-24 16:51:47.496058: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-24 16:51:47.520283: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-24 16:51:47.520313: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-24 16:51:47.520988: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-24 16:51:47.524902: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-24 16:51:47.525340: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-24 16:51:48.108641: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\n\\nimport sys\\n\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.preprocessing import OneHotEncoder\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.impute import SimpleImputer\\nfrom sklearn.metrics import log_loss\\nfrom sklearn.linear_model import BayesianRidge, LinearRegression, Ridge\\nfrom scipy.optimize import approx_fprime, minimize\\nfrom scipy.special import expit\\nfrom scipy.stats import multivariate_normal\\n\\nsys.path.append(\\\"/home/capitaine/01_projects/2023/cr_model/cr-model-research\\\")\\nfrom cr_model.model.bayesian_models import BayesianLogisticRegression\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\n\\nimport sys\\n\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.preprocessing import OneHotEncoder\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.impute import SimpleImputer\\nfrom sklearn.metrics import log_loss\\nfrom sklearn.linear_model import BayesianRidge, LinearRegression, Ridge\\nfrom scipy.optimize import approx_fprime, minimize\\nfrom scipy.special import expit\\nfrom scipy.stats import multivariate_normal\\n\\nsys.path.append(\\\"/home/capitaine/01_projects/2023/cr_model/cr-model-research\\\")\\nfrom cr_model.model.bayesian_models import BayesianLogisticRegression\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import BayesianRidge, LinearRegression, Ridge\n",
    "from scipy.optimize import approx_fprime, minimize\n",
    "from scipy.special import expit\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "sys.path.append(\"/home/capitaine/01_projects/2023/cr_model/cr-model-research\")\n",
    "from cr_model.model.bayesian_models import BayesianLogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a63f4e",
   "metadata": {},
   "source": [
    "___\n",
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8ede3e",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb6b69e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"def loss(\\n    beta: np.ndarray,\\n    X: np.ndarray,\\n    y: np.ndarray,\\n    m: np.ndarray,\\n    q: np.ndarray,\\n    r: float,\\n):\\n    linear_pred = np.dot(X, beta)\\n    y_pred = expit(linear_pred)\\n\\n    weights = np.ones(y.shape)\\n    weights[y == 0] = 1 / r\\n\\n    loss = log_loss(y, y_pred, sample_weight=weights, normalize=False) + 0.5 * np.dot(\\n        np.multiply(q, np.subtract(beta, m)), np.subtract(beta, m)\\n    ) + 0.5 * (np.sum(np.log(1 / q)) + len(q) * np.log(2 * np.pi))\\n\\n    return loss\\n\\n\\ndef jac(\\n    beta: np.ndarray,\\n    X: np.ndarray,\\n    y: np.ndarray,\\n    m: np.ndarray,\\n    q: np.ndarray,\\n    r: float,\\n):\\n    linear_pred = np.dot(X, beta)\\n    y_pred = expit(linear_pred)\\n\\n    weights = np.ones(y.shape)\\n    weights[y == 0] = 1 / r\\n\\n    jac = np.add(\\n        -np.dot(weights * (y - y_pred), X),\\n        np.multiply(q, np.subtract(beta, m)),\\n    )\\n\\n    return jac\\n\\n\\ndef hess(\\n    beta: np.ndarray,\\n    X: np.ndarray,\\n    y: np.ndarray,\\n    m: np.ndarray,\\n    q: np.ndarray,\\n    r: float,\\n):\\n    weights = np.ones(y.shape)\\n    weights[y == 0] = 1 / r\\n\\n    linear_pred = np.dot(X, beta)\\n    y_pred = expit(linear_pred)\\n\\n    hess = np.diag(q) + np.matmul(\\n        np.matmul(\\n            X.T,\\n            np.diag(np.multiply(weights, np.multiply(y_pred, 1 - y_pred))),\\n        ),\\n        X,\\n    )\\n    return hess\";\n",
       "                var nbb_formatted_code = \"def loss(\\n    beta: np.ndarray,\\n    X: np.ndarray,\\n    y: np.ndarray,\\n    m: np.ndarray,\\n    q: np.ndarray,\\n    r: float,\\n):\\n    linear_pred = np.dot(X, beta)\\n    y_pred = expit(linear_pred)\\n\\n    weights = np.ones(y.shape)\\n    weights[y == 0] = 1 / r\\n\\n    loss = (\\n        log_loss(y, y_pred, sample_weight=weights, normalize=False)\\n        + 0.5 * np.dot(np.multiply(q, np.subtract(beta, m)), np.subtract(beta, m))\\n        + 0.5 * (np.sum(np.log(1 / q)) + len(q) * np.log(2 * np.pi))\\n    )\\n\\n    return loss\\n\\n\\ndef jac(\\n    beta: np.ndarray,\\n    X: np.ndarray,\\n    y: np.ndarray,\\n    m: np.ndarray,\\n    q: np.ndarray,\\n    r: float,\\n):\\n    linear_pred = np.dot(X, beta)\\n    y_pred = expit(linear_pred)\\n\\n    weights = np.ones(y.shape)\\n    weights[y == 0] = 1 / r\\n\\n    jac = np.add(\\n        -np.dot(weights * (y - y_pred), X),\\n        np.multiply(q, np.subtract(beta, m)),\\n    )\\n\\n    return jac\\n\\n\\ndef hess(\\n    beta: np.ndarray,\\n    X: np.ndarray,\\n    y: np.ndarray,\\n    m: np.ndarray,\\n    q: np.ndarray,\\n    r: float,\\n):\\n    weights = np.ones(y.shape)\\n    weights[y == 0] = 1 / r\\n\\n    linear_pred = np.dot(X, beta)\\n    y_pred = expit(linear_pred)\\n\\n    hess = np.diag(q) + np.matmul(\\n        np.matmul(\\n            X.T,\\n            np.diag(np.multiply(weights, np.multiply(y_pred, 1 - y_pred))),\\n        ),\\n        X,\\n    )\\n    return hess\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def loss(\n",
    "    beta: np.ndarray,\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    m: np.ndarray,\n",
    "    q: np.ndarray,\n",
    "    r: float,\n",
    "):\n",
    "    linear_pred = np.dot(X, beta)\n",
    "    y_pred = expit(linear_pred)\n",
    "\n",
    "    weights = np.ones(y.shape)\n",
    "    weights[y == 0] = 1 / r\n",
    "\n",
    "    loss = (\n",
    "        log_loss(y, y_pred, sample_weight=weights, normalize=False)\n",
    "        + 0.5 * np.dot(np.multiply(q, np.subtract(beta, m)), np.subtract(beta, m))\n",
    "        + 0.5 * (np.sum(np.log(1 / q)) + len(q) * np.log(2 * np.pi))\n",
    "    )\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def jac(\n",
    "    beta: np.ndarray,\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    m: np.ndarray,\n",
    "    q: np.ndarray,\n",
    "    r: float,\n",
    "):\n",
    "    linear_pred = np.dot(X, beta)\n",
    "    y_pred = expit(linear_pred)\n",
    "\n",
    "    weights = np.ones(y.shape)\n",
    "    weights[y == 0] = 1 / r\n",
    "\n",
    "    jac = np.add(\n",
    "        -np.dot(weights * (y - y_pred), X),\n",
    "        np.multiply(q, np.subtract(beta, m)),\n",
    "    )\n",
    "\n",
    "    return jac\n",
    "\n",
    "\n",
    "def hess(\n",
    "    beta: np.ndarray,\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    m: np.ndarray,\n",
    "    q: np.ndarray,\n",
    "    r: float,\n",
    "):\n",
    "    weights = np.ones(y.shape)\n",
    "    weights[y == 0] = 1 / r\n",
    "\n",
    "    linear_pred = np.dot(X, beta)\n",
    "    y_pred = expit(linear_pred)\n",
    "\n",
    "    hess = np.diag(q) + np.matmul(\n",
    "        np.matmul(\n",
    "            X.T,\n",
    "            np.diag(np.multiply(weights, np.multiply(y_pred, 1 - y_pred))),\n",
    "        ),\n",
    "        X,\n",
    "    )\n",
    "    return hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf96e6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"beta = np.random.normal(size=4)\\nX = np.random.normal(size=(10, 4))\\ny = np.random.choice([0, 1], size=10)\\nm = np.random.normal(size=4)\\nq = np.exp(np.random.normal(size=4))\\nr = 1\";\n",
       "                var nbb_formatted_code = \"beta = np.random.normal(size=4)\\nX = np.random.normal(size=(10, 4))\\ny = np.random.choice([0, 1], size=10)\\nm = np.random.normal(size=4)\\nq = np.exp(np.random.normal(size=4))\\nr = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta = np.random.normal(size=4)\n",
    "X = np.random.normal(size=(10, 4))\n",
    "y = np.random.choice([0, 1], size=10)\n",
    "m = np.random.normal(size=4)\n",
    "q = np.exp(np.random.normal(size=4))\n",
    "r = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e65efbee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.21219373, -8.2543025 ,  1.67136264,  1.19512987])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"approx_fprime(\\n    beta,\\n    loss,\\n    1.4901161193847656e-08,\\n    *(X, y, m, q, r),\\n)\";\n",
       "                var nbb_formatted_code = \"approx_fprime(\\n    beta,\\n    loss,\\n    1.4901161193847656e-08,\\n    *(X, y, m, q, r),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "approx_fprime(\n",
    "    beta,\n",
    "    loss,\n",
    "    1.4901161193847656e-08,\n",
    "    *(X, y, m, q, r),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06db56f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.21219364, -8.25430268,  1.6713624 ,  1.19512984])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"jac(beta, X, y, m, q, r)\";\n",
       "                var nbb_formatted_code = \"jac(beta, X, y, m, q, r)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jac(beta, X, y, m, q, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d39761fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.03404027,  0.65171725, -0.03051043,  0.45034492],\n",
       "       [ 0.65171719,  3.54062629, -0.16870368,  0.43155241],\n",
       "       [-0.03051038, -0.16870359,  1.10525566, -0.26152341],\n",
       "       [ 0.45034501,  0.43155238, -0.26152341,  3.80380088]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"approx_fprime(\\n    beta,\\n    jac,\\n    1.4901161193847656e-08,\\n    *(X, y, m, q, r),\\n)\";\n",
       "                var nbb_formatted_code = \"approx_fprime(\\n    beta,\\n    jac,\\n    1.4901161193847656e-08,\\n    *(X, y, m, q, r),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "approx_fprime(\n",
    "    beta,\n",
    "    jac,\n",
    "    1.4901161193847656e-08,\n",
    "    *(X, y, m, q, r),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94a48202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.03404035,  0.65171727, -0.03051039,  0.45034501],\n",
       "       [ 0.65171727,  3.54062639, -0.16870359,  0.43155239],\n",
       "       [-0.03051039, -0.16870359,  1.10525566, -0.26152342],\n",
       "       [ 0.45034501,  0.43155239, -0.26152342,  3.80380089]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"hess(beta, X, y, m, q, r)\";\n",
       "                var nbb_formatted_code = \"hess(beta, X, y, m, q, r)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hess(beta, X, y, m, q, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6562870c",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2e01085f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 141;\n",
       "                var nbb_unformatted_code = \"def loss(\\n    beta: np.ndarray,\\n    X: np.ndarray,\\n    y: np.ndarray,\\n    m: np.ndarray,\\n    q: np.ndarray,\\n    r: float,\\n    scale=None,\\n):\\n    linear_pred = np.dot(X, beta)\\n    y_pred = linear_pred\\n\\n    if scale is None:\\n        scale = _estimate_scale(X, y, y_pred, r, bool(np.all(q == 0)))\\n\\n    weights = np.ones(y.shape)\\n    weights[y == 0] = 1 / r\\n\\n    loss = (\\n        np.sum(\\n            np.multiply(\\n                weights,\\n                1 / 2 * np.divide(np.power(np.subtract(y, y_pred), 2), scale),\\n            )\\n        )\\n        - np.sum(np.log(weights)) / 2\\n        + 0.5 * len(y) * (np.log(scale) + np.log(2 * np.pi))\\n        + np.sum(\\n            1\\n            / 2\\n            * np.multiply(\\n                np.power(np.subtract(beta, m), 2),\\n                q,\\n            )\\n        )\\n        + 0.5 * (np.sum(np.log(1 / q)) + len(q) * np.log(2 * np.pi))\\n    )\\n\\n    return loss\\n\\n\\ndef jac(\\n    beta: np.ndarray,\\n    X: np.ndarray,\\n    y: np.ndarray,\\n    m: np.ndarray,\\n    q: np.ndarray,\\n    r: float,\\n    scale=None,\\n):\\n    linear_pred = np.dot(X, beta)\\n    y_pred = linear_pred\\n\\n    if scale is None:\\n        scale = _estimate_scale(X, y, y_pred, r, bool(np.all(q == 0)))\\n\\n    weights = np.ones(y.shape)\\n    weights[y == 0] = 1 / r\\n\\n    jac = -np.sum(\\n        np.multiply(\\n            np.expand_dims(\\n                np.multiply(\\n                    weights,\\n                    np.divide(np.subtract(y, y_pred), scale),\\n                ),\\n                axis=1,\\n            ),\\n            np.multiply(\\n                np.expand_dims(\\n                    np.array([1] * len(y_pred)),\\n                    axis=1,\\n                ),\\n                X,\\n            ),\\n        ),\\n        axis=0,\\n    ) + np.multiply(np.subtract(beta, m), q)\\n\\n    return jac\\n\\n\\ndef hess(\\n    beta: np.ndarray,\\n    X: np.ndarray,\\n    y: np.ndarray,\\n    m: np.ndarray,\\n    q: np.ndarray,\\n    r: float,\\n    scale=None,\\n):\\n    linear_pred = np.dot(X, beta)\\n    y_pred = linear_pred\\n\\n    if scale is None:\\n        scale = _estimate_scale(X, y, y_pred, r, bool(np.all(q == 0)))\\n\\n    weights = np.ones(y.shape)\\n    weights[y == 0] = 1 / r\\n\\n    hess = np.add(\\n        np.matmul(\\n            np.matmul(X.T, np.diag(weights) / scale),\\n            X,\\n        ),\\n        np.diag(q),\\n    )\\n    return hess\\n\\n\\ndef _estimate_scale(\\n    X: np.ndarray,\\n    y: np.ndarray,\\n    y_pred: np.ndarray,\\n    r: float,\\n    without_prior: bool,\\n):\\n    weights = np.ones(y.shape)\\n    weights[y == 0] = 1 / r\\n    if without_prior:\\n        df_resid = np.sum(weights) - X.shape[1]\\n    else:\\n        df_resid = np.sum(weights)\\n\\n    if df_resid <= 0:\\n        raise ValueError(f\\\"Scale estimation is wrong since df_resid={df_resid}.\\\")\\n\\n    return np.sum(np.multiply(np.power(y - y_pred, 2), weights)) / df_resid\";\n",
       "                var nbb_formatted_code = \"def loss(\\n    beta: np.ndarray,\\n    X: np.ndarray,\\n    y: np.ndarray,\\n    m: np.ndarray,\\n    q: np.ndarray,\\n    r: float,\\n    scale=None,\\n):\\n    linear_pred = np.dot(X, beta)\\n    y_pred = linear_pred\\n\\n    if scale is None:\\n        scale = _estimate_scale(X, y, y_pred, r, bool(np.all(q == 0)))\\n\\n    weights = np.ones(y.shape)\\n    weights[y == 0] = 1 / r\\n\\n    loss = (\\n        np.sum(\\n            np.multiply(\\n                weights,\\n                1 / 2 * np.divide(np.power(np.subtract(y, y_pred), 2), scale),\\n            )\\n        )\\n        - np.sum(np.log(weights)) / 2\\n        + 0.5 * len(y) * (np.log(scale) + np.log(2 * np.pi))\\n        + np.sum(\\n            1\\n            / 2\\n            * np.multiply(\\n                np.power(np.subtract(beta, m), 2),\\n                q,\\n            )\\n        )\\n        + 0.5 * (np.sum(np.log(1 / q)) + len(q) * np.log(2 * np.pi))\\n    )\\n\\n    return loss\\n\\n\\ndef jac(\\n    beta: np.ndarray,\\n    X: np.ndarray,\\n    y: np.ndarray,\\n    m: np.ndarray,\\n    q: np.ndarray,\\n    r: float,\\n    scale=None,\\n):\\n    linear_pred = np.dot(X, beta)\\n    y_pred = linear_pred\\n\\n    if scale is None:\\n        scale = _estimate_scale(X, y, y_pred, r, bool(np.all(q == 0)))\\n\\n    weights = np.ones(y.shape)\\n    weights[y == 0] = 1 / r\\n\\n    jac = -np.sum(\\n        np.multiply(\\n            np.expand_dims(\\n                np.multiply(\\n                    weights,\\n                    np.divide(np.subtract(y, y_pred), scale),\\n                ),\\n                axis=1,\\n            ),\\n            np.multiply(\\n                np.expand_dims(\\n                    np.array([1] * len(y_pred)),\\n                    axis=1,\\n                ),\\n                X,\\n            ),\\n        ),\\n        axis=0,\\n    ) + np.multiply(np.subtract(beta, m), q)\\n\\n    return jac\\n\\n\\ndef hess(\\n    beta: np.ndarray,\\n    X: np.ndarray,\\n    y: np.ndarray,\\n    m: np.ndarray,\\n    q: np.ndarray,\\n    r: float,\\n    scale=None,\\n):\\n    linear_pred = np.dot(X, beta)\\n    y_pred = linear_pred\\n\\n    if scale is None:\\n        scale = _estimate_scale(X, y, y_pred, r, bool(np.all(q == 0)))\\n\\n    weights = np.ones(y.shape)\\n    weights[y == 0] = 1 / r\\n\\n    hess = np.add(\\n        np.matmul(\\n            np.matmul(X.T, np.diag(weights) / scale),\\n            X,\\n        ),\\n        np.diag(q),\\n    )\\n    return hess\\n\\n\\ndef _estimate_scale(\\n    X: np.ndarray,\\n    y: np.ndarray,\\n    y_pred: np.ndarray,\\n    r: float,\\n    without_prior: bool,\\n):\\n    weights = np.ones(y.shape)\\n    weights[y == 0] = 1 / r\\n    if without_prior:\\n        df_resid = np.sum(weights) - X.shape[1]\\n    else:\\n        df_resid = np.sum(weights)\\n\\n    if df_resid <= 0:\\n        raise ValueError(f\\\"Scale estimation is wrong since df_resid={df_resid}.\\\")\\n\\n    return np.sum(np.multiply(np.power(y - y_pred, 2), weights)) / df_resid\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def loss(\n",
    "    beta: np.ndarray,\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    m: np.ndarray,\n",
    "    q: np.ndarray,\n",
    "    r: float,\n",
    "    scale=None,\n",
    "):\n",
    "    linear_pred = np.dot(X, beta)\n",
    "    y_pred = linear_pred\n",
    "\n",
    "    if scale is None:\n",
    "        scale = _estimate_scale(X, y, y_pred, r, bool(np.all(q == 0)))\n",
    "\n",
    "    weights = np.ones(y.shape)\n",
    "    weights[y == 0] = 1 / r\n",
    "\n",
    "    loss = (\n",
    "        np.sum(\n",
    "            np.multiply(\n",
    "                weights,\n",
    "                1 / 2 * np.divide(np.power(np.subtract(y, y_pred), 2), scale),\n",
    "            )\n",
    "        )\n",
    "        - np.sum(np.log(weights)) / 2\n",
    "        + 0.5 * len(y) * (np.log(scale) + np.log(2 * np.pi))\n",
    "        + np.sum(\n",
    "            1\n",
    "            / 2\n",
    "            * np.multiply(\n",
    "                np.power(np.subtract(beta, m), 2),\n",
    "                q,\n",
    "            )\n",
    "        )\n",
    "        + 0.5 * (np.sum(np.log(1 / q)) + len(q) * np.log(2 * np.pi))\n",
    "    )\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def jac(\n",
    "    beta: np.ndarray,\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    m: np.ndarray,\n",
    "    q: np.ndarray,\n",
    "    r: float,\n",
    "    scale=None,\n",
    "):\n",
    "    linear_pred = np.dot(X, beta)\n",
    "    y_pred = linear_pred\n",
    "\n",
    "    if scale is None:\n",
    "        scale = _estimate_scale(X, y, y_pred, r, bool(np.all(q == 0)))\n",
    "\n",
    "    weights = np.ones(y.shape)\n",
    "    weights[y == 0] = 1 / r\n",
    "\n",
    "    jac = -np.sum(\n",
    "        np.multiply(\n",
    "            np.expand_dims(\n",
    "                np.multiply(\n",
    "                    weights,\n",
    "                    np.divide(np.subtract(y, y_pred), scale),\n",
    "                ),\n",
    "                axis=1,\n",
    "            ),\n",
    "            np.multiply(\n",
    "                np.expand_dims(\n",
    "                    np.array([1] * len(y_pred)),\n",
    "                    axis=1,\n",
    "                ),\n",
    "                X,\n",
    "            ),\n",
    "        ),\n",
    "        axis=0,\n",
    "    ) + np.multiply(np.subtract(beta, m), q)\n",
    "\n",
    "    return jac\n",
    "\n",
    "\n",
    "def hess(\n",
    "    beta: np.ndarray,\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    m: np.ndarray,\n",
    "    q: np.ndarray,\n",
    "    r: float,\n",
    "    scale=None,\n",
    "):\n",
    "    linear_pred = np.dot(X, beta)\n",
    "    y_pred = linear_pred\n",
    "\n",
    "    if scale is None:\n",
    "        scale = _estimate_scale(X, y, y_pred, r, bool(np.all(q == 0)))\n",
    "\n",
    "    weights = np.ones(y.shape)\n",
    "    weights[y == 0] = 1 / r\n",
    "\n",
    "    hess = np.add(\n",
    "        np.matmul(\n",
    "            np.matmul(X.T, np.diag(weights) / scale),\n",
    "            X,\n",
    "        ),\n",
    "        np.diag(q),\n",
    "    )\n",
    "    return hess\n",
    "\n",
    "\n",
    "def _estimate_scale(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    y_pred: np.ndarray,\n",
    "    r: float,\n",
    "    without_prior: bool,\n",
    "):\n",
    "    weights = np.ones(y.shape)\n",
    "    weights[y == 0] = 1 / r\n",
    "    if without_prior:\n",
    "        df_resid = np.sum(weights) - X.shape[1]\n",
    "    else:\n",
    "        df_resid = np.sum(weights)\n",
    "\n",
    "    if df_resid <= 0:\n",
    "        raise ValueError(f\"Scale estimation is wrong since df_resid={df_resid}.\")\n",
    "\n",
    "    return np.sum(np.multiply(np.power(y - y_pred, 2), weights)) / df_resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "97449143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 152;\n",
       "                var nbb_unformatted_code = \"beta = np.random.normal(size=4)\\nX = np.random.normal(size=(10, 4))\\ny = np.random.normal(size=10)\\nm = np.random.normal(size=4)\\nq = np.exp(np.random.normal(size=4))\\nr = 1\";\n",
       "                var nbb_formatted_code = \"beta = np.random.normal(size=4)\\nX = np.random.normal(size=(10, 4))\\ny = np.random.normal(size=10)\\nm = np.random.normal(size=4)\\nq = np.exp(np.random.normal(size=4))\\nr = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta = np.random.normal(size=4)\n",
    "X = np.random.normal(size=(10, 4))\n",
    "y = np.random.normal(size=10)\n",
    "m = np.random.normal(size=4)\n",
    "q = np.exp(np.random.normal(size=4))\n",
    "r = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "aa049c1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.601855668276723"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 153;\n",
       "                var nbb_unformatted_code = \"loss(beta, *(X, y, m, q, r, 2))\";\n",
       "                var nbb_formatted_code = \"loss(beta, *(X, y, m, q, r, 2))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss(beta, *(X, y, m, q, r, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9c7317b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-27.601855668276716"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 154;\n",
       "                var nbb_unformatted_code = \"multivariate_normal.logpdf(\\n    y, mean=np.dot(X, beta), cov=2 * np.eye(len(y))\\n) + multivariate_normal.logpdf(beta, mean=m, cov=np.diag(1 / q))\";\n",
       "                var nbb_formatted_code = \"multivariate_normal.logpdf(\\n    y, mean=np.dot(X, beta), cov=2 * np.eye(len(y))\\n) + multivariate_normal.logpdf(beta, mean=m, cov=np.diag(1 / q))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "multivariate_normal.logpdf(\n",
    "    y, mean=np.dot(X, beta), cov=2 * np.eye(len(y))\n",
    ") + multivariate_normal.logpdf(beta, mean=m, cov=np.diag(1 / q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2d1cd1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.93074703,  2.35958982, -6.39777231, -2.75568271])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 155;\n",
       "                var nbb_unformatted_code = \"approx_fprime(\\n    beta,\\n    loss,\\n    1.4901161193847656e-08,\\n    *(X, y, m, q, r, 2),\\n)\";\n",
       "                var nbb_formatted_code = \"approx_fprime(\\n    beta,\\n    loss,\\n    1.4901161193847656e-08,\\n    *(X, y, m, q, r, 2),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "approx_fprime(\n",
    "    beta,\n",
    "    loss,\n",
    "    1.4901161193847656e-08,\n",
    "    *(X, y, m, q, r, 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "230dd07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.93074679,  2.35959014, -6.39777206, -2.75568278])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 156;\n",
       "                var nbb_unformatted_code = \"jac(beta, X, y, m, q, r, 2)\";\n",
       "                var nbb_formatted_code = \"jac(beta, X, y, m, q, r, 2)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jac(beta, X, y, m, q, r, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4e01e453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.62139761,  3.1840551 , -1.7851456 ,  0.94606332],\n",
       "       [ 3.18405515,  5.21584272, -1.29461098,  0.94209462],\n",
       "       [-1.78514564, -1.29461098,  3.51416832,  0.13655412],\n",
       "       [ 0.94606331,  0.94209462,  0.13655412,  3.53591296]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 157;\n",
       "                var nbb_unformatted_code = \"approx_fprime(\\n    beta,\\n    jac,\\n    1.4901161193847656e-08,\\n    *(X, y, m, q, r, 2),\\n)\";\n",
       "                var nbb_formatted_code = \"approx_fprime(\\n    beta,\\n    jac,\\n    1.4901161193847656e-08,\\n    *(X, y, m, q, r, 2),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "approx_fprime(\n",
    "    beta,\n",
    "    jac,\n",
    "    1.4901161193847656e-08,\n",
    "    *(X, y, m, q, r, 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1c49f0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.6213976 ,  3.18405509, -1.78514563,  0.94606329],\n",
       "       [ 3.18405509,  5.21584269, -1.29461102,  0.94209462],\n",
       "       [-1.78514563, -1.29461102,  3.51416831,  0.13655412],\n",
       "       [ 0.94606329,  0.94209462,  0.13655412,  3.53591296]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 158;\n",
       "                var nbb_unformatted_code = \"hess(beta, X, y, m, q, r, 2)\";\n",
       "                var nbb_formatted_code = \"hess(beta, X, y, m, q, r, 2)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hess(beta, X, y, m, q, r, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6188d88",
   "metadata": {},
   "source": [
    "## Bayesian loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5838e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"def func_with_bias(log_sigma2, X, y):\\n    n_feat = X.shape[1]\\n    log_sigma2 = np.array([log_sigma2[0]] * n_feat)\\n    diag_sigma2 = np.exp(log_sigma2)\\n\\n    m = np.array([0] * n_feat)\\n    q = 1 / diag_sigma2\\n    r = 1\\n\\n    res = minimize(\\n        loss,\\n        np.array([0] * n_feat),\\n        args=(X, y, m, q, r),\\n        method=\\\"L-BFGS-B\\\",\\n        jac=jac,\\n    )\\n\\n    theta_star = res.x\\n\\n    H = hess(theta_star, X, y, m, q, r)\\n\\n    out = (\\n        loss(theta_star, X, y, m, q, r)\\n        - 0.5 * n_feat * np.log(2 * np.pi)\\n        + 0.5 * np.linalg.slogdet(H)[1]\\n    )\\n    return out\\n\\n\\ndef jac_func_with_bias(log_sigma2, X, y):\\n    h = np.log(1 + 1e-1)\\n    jac_list = []\\n    for ii in range(len(log_sigma2)):\\n        xk = np.copy(log_sigma2)\\n        xk[ii] += h\\n        fk_plus_h = func_with_bias(xk, X, y)\\n        xk[ii] -= 2 * h\\n        fk_minus_h = func_with_bias(xk, X, y)\\n        jac_list.append((fk_plus_h - fk_minus_h) / 2 * h)\\n    return np.array(jac_list)\";\n",
       "                var nbb_formatted_code = \"def func_with_bias(log_sigma2, X, y):\\n    n_feat = X.shape[1]\\n    log_sigma2 = np.array([log_sigma2[0]] * n_feat)\\n    diag_sigma2 = np.exp(log_sigma2)\\n\\n    m = np.array([0] * n_feat)\\n    q = 1 / diag_sigma2\\n    r = 1\\n\\n    res = minimize(\\n        loss,\\n        np.array([0] * n_feat),\\n        args=(X, y, m, q, r),\\n        method=\\\"L-BFGS-B\\\",\\n        jac=jac,\\n    )\\n\\n    theta_star = res.x\\n\\n    H = hess(theta_star, X, y, m, q, r)\\n\\n    out = (\\n        loss(theta_star, X, y, m, q, r)\\n        - 0.5 * n_feat * np.log(2 * np.pi)\\n        + 0.5 * np.linalg.slogdet(H)[1]\\n    )\\n    return out\\n\\n\\ndef jac_func_with_bias(log_sigma2, X, y):\\n    h = np.log(1 + 1e-1)\\n    jac_list = []\\n    for ii in range(len(log_sigma2)):\\n        xk = np.copy(log_sigma2)\\n        xk[ii] += h\\n        fk_plus_h = func_with_bias(xk, X, y)\\n        xk[ii] -= 2 * h\\n        fk_minus_h = func_with_bias(xk, X, y)\\n        jac_list.append((fk_plus_h - fk_minus_h) / 2 * h)\\n    return np.array(jac_list)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def func_with_bias(log_sigma2, X, y):\n",
    "    n_feat = X.shape[1]\n",
    "    log_sigma2 = np.array([log_sigma2[0]] * n_feat)\n",
    "    diag_sigma2 = np.exp(log_sigma2)\n",
    "\n",
    "    m = np.array([0] * n_feat)\n",
    "    q = 1 / diag_sigma2\n",
    "    r = 1\n",
    "\n",
    "    res = minimize(\n",
    "        loss,\n",
    "        np.array([0] * n_feat),\n",
    "        args=(X, y, m, q, r),\n",
    "        method=\"L-BFGS-B\",\n",
    "        jac=jac,\n",
    "    )\n",
    "\n",
    "    theta_star = res.x\n",
    "\n",
    "    H = hess(theta_star, X, y, m, q, r)\n",
    "\n",
    "    out = (\n",
    "        loss(theta_star, X, y, m, q, r)\n",
    "        - 0.5 * n_feat * np.log(2 * np.pi)\n",
    "        + 0.5 * np.linalg.slogdet(H)[1]\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "def jac_func_with_bias(log_sigma2, X, y):\n",
    "    h = np.log(1 + 1e-1)\n",
    "    jac_list = []\n",
    "    for ii in range(len(log_sigma2)):\n",
    "        xk = np.copy(log_sigma2)\n",
    "        xk[ii] += h\n",
    "        fk_plus_h = func_with_bias(xk, X, y)\n",
    "        xk[ii] -= 2 * h\n",
    "        fk_minus_h = func_with_bias(xk, X, y)\n",
    "        jac_list.append((fk_plus_h - fk_minus_h) / 2 * h)\n",
    "    return np.array(jac_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665f72ff",
   "metadata": {},
   "source": [
    "___\n",
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab81624b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"data = pd.read_csv(\\n    \\\"/home/capitaine/01_projects/2024/bayesian_optimization/data/titanic/train.csv\\\"\\n)\\ny = data.pop(\\\"Survived\\\")\\ndata[\\\"CabinCat\\\"] = data[\\\"Cabin\\\"].astype(str).str[0]\\ndata[\\\"Embarked\\\"] = data[\\\"Embarked\\\"].fillna(\\\"unknown\\\")\\nX = data[[\\\"Pclass\\\", \\\"Sex\\\", \\\"Embarked\\\", \\\"CabinCat\\\", \\\"Age\\\", \\\"SibSp\\\", \\\"Parch\\\"]].copy()\";\n",
       "                var nbb_formatted_code = \"data = pd.read_csv(\\n    \\\"/home/capitaine/01_projects/2024/bayesian_optimization/data/titanic/train.csv\\\"\\n)\\ny = data.pop(\\\"Survived\\\")\\ndata[\\\"CabinCat\\\"] = data[\\\"Cabin\\\"].astype(str).str[0]\\ndata[\\\"Embarked\\\"] = data[\\\"Embarked\\\"].fillna(\\\"unknown\\\")\\nX = data[[\\\"Pclass\\\", \\\"Sex\\\", \\\"Embarked\\\", \\\"CabinCat\\\", \\\"Age\\\", \\\"SibSp\\\", \\\"Parch\\\"]].copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    \"/home/capitaine/01_projects/2024/bayesian_optimization/data/titanic/train.csv\"\n",
    ")\n",
    "y = data.pop(\"Survived\")\n",
    "data[\"CabinCat\"] = data[\"Cabin\"].astype(str).str[0]\n",
    "data[\"Embarked\"] = data[\"Embarked\"].fillna(\"unknown\")\n",
    "X = data[[\"Pclass\", \"Sex\", \"Embarked\", \"CabinCat\", \"Age\", \"SibSp\", \"Parch\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab81dd",
   "metadata": {},
   "source": [
    "___\n",
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27829427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"preprocessor = ColumnTransformer(\\n    [\\n        (\\n            \\\"categorical_features_wo_nan\\\",\\n            OneHotEncoder(handle_unknown=\\\"ignore\\\", sparse_output=False),\\n            [\\\"Pclass\\\", \\\"Sex\\\", \\\"Embarked\\\", \\\"CabinCat\\\"],\\n        ),\\n        (\\n            \\\"numerical_features_w_nan\\\",\\n            Pipeline(\\n                [\\n                    (\\\"imputer\\\", SimpleImputer(strategy=\\\"mean\\\")),\\n                ]\\n            ),\\n            [\\\"Age\\\"],\\n        ),\\n    ],\\n    remainder=\\\"passthrough\\\",\\n)\\npreprocessor.set_output(transform=\\\"pandas\\\")\\npipe = Pipeline(\\n    [\\n        (\\\"preprocessing\\\", preprocessor),\\n        (\\\"classifier\\\", LogisticRegression(fit_intercept=False)),\\n    ]\\n)\";\n",
       "                var nbb_formatted_code = \"preprocessor = ColumnTransformer(\\n    [\\n        (\\n            \\\"categorical_features_wo_nan\\\",\\n            OneHotEncoder(handle_unknown=\\\"ignore\\\", sparse_output=False),\\n            [\\\"Pclass\\\", \\\"Sex\\\", \\\"Embarked\\\", \\\"CabinCat\\\"],\\n        ),\\n        (\\n            \\\"numerical_features_w_nan\\\",\\n            Pipeline(\\n                [\\n                    (\\\"imputer\\\", SimpleImputer(strategy=\\\"mean\\\")),\\n                ]\\n            ),\\n            [\\\"Age\\\"],\\n        ),\\n    ],\\n    remainder=\\\"passthrough\\\",\\n)\\npreprocessor.set_output(transform=\\\"pandas\\\")\\npipe = Pipeline(\\n    [\\n        (\\\"preprocessing\\\", preprocessor),\\n        (\\\"classifier\\\", LogisticRegression(fit_intercept=False)),\\n    ]\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\n",
    "            \"categorical_features_wo_nan\",\n",
    "            OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
    "            [\"Pclass\", \"Sex\", \"Embarked\", \"CabinCat\"],\n",
    "        ),\n",
    "        (\n",
    "            \"numerical_features_w_nan\",\n",
    "            Pipeline(\n",
    "                [\n",
    "                    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "                ]\n",
    "            ),\n",
    "            [\"Age\"],\n",
    "        ),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "preprocessor.set_output(transform=\"pandas\")\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", preprocessor),\n",
    "        (\"classifier\", LogisticRegression(fit_intercept=False)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0b57a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"param_grid = {\\n    \\\"classifier__C\\\": [\\n        0.001,\\n        0.1,\\n        0.2,\\n        0.5,\\n        1,\\n        1.1,\\n        1.2,\\n        1.3,\\n        1.4,\\n        1.5,\\n        1.6,\\n        2,\\n        3,\\n        4,\\n        5,\\n        6,\\n        7,\\n        8,\\n        9,\\n        10,\\n        100,\\n        1000,\\n    ],\\n    \\\"classifier__fit_intercept\\\": [False],\\n}\";\n",
       "                var nbb_formatted_code = \"param_grid = {\\n    \\\"classifier__C\\\": [\\n        0.001,\\n        0.1,\\n        0.2,\\n        0.5,\\n        1,\\n        1.1,\\n        1.2,\\n        1.3,\\n        1.4,\\n        1.5,\\n        1.6,\\n        2,\\n        3,\\n        4,\\n        5,\\n        6,\\n        7,\\n        8,\\n        9,\\n        10,\\n        100,\\n        1000,\\n    ],\\n    \\\"classifier__fit_intercept\\\": [False],\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"classifier__C\": [\n",
    "        0.001,\n",
    "        0.1,\n",
    "        0.2,\n",
    "        0.5,\n",
    "        1,\n",
    "        1.1,\n",
    "        1.2,\n",
    "        1.3,\n",
    "        1.4,\n",
    "        1.5,\n",
    "        1.6,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        6,\n",
    "        7,\n",
    "        8,\n",
    "        9,\n",
    "        10,\n",
    "        100,\n",
    "        1000,\n",
    "    ],\n",
    "    \"classifier__fit_intercept\": [False],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f63af0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"grid_search = GridSearchCV(pipe, param_grid, return_train_score=True)\";\n",
       "                var nbb_formatted_code = \"grid_search = GridSearchCV(pipe, param_grid, return_train_score=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipe, param_grid, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c04aea2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/capitaine/01_projects/2023/cr_model/venv_cr_model/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                        ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                          transformers=[(&#x27;categorical_features_wo_nan&#x27;,\n",
       "                                                                         OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                       sparse_output=False),\n",
       "                                                                         [&#x27;Pclass&#x27;,\n",
       "                                                                          &#x27;Sex&#x27;,\n",
       "                                                                          &#x27;Embarked&#x27;,\n",
       "                                                                          &#x27;CabinCat&#x27;]),\n",
       "                                                                        (&#x27;numerical_features_w_nan&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                          SimpleImputer())]),\n",
       "                                                                         [&#x27;Age&#x27;])])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        LogisticRegression(fit_intercept=False))]),\n",
       "             param_grid={&#x27;classifier__C&#x27;: [0.001, 0.1, 0.2, 0.5, 1, 1.1, 1.2,\n",
       "                                           1.3, 1.4, 1.5, 1.6, 2, 3, 4, 5, 6, 7,\n",
       "                                           8, 9, 10, 100, 1000],\n",
       "                         &#x27;classifier__fit_intercept&#x27;: [False]},\n",
       "             return_train_score=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                        ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                          transformers=[(&#x27;categorical_features_wo_nan&#x27;,\n",
       "                                                                         OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                       sparse_output=False),\n",
       "                                                                         [&#x27;Pclass&#x27;,\n",
       "                                                                          &#x27;Sex&#x27;,\n",
       "                                                                          &#x27;Embarked&#x27;,\n",
       "                                                                          &#x27;CabinCat&#x27;]),\n",
       "                                                                        (&#x27;numerical_features_w_nan&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                          SimpleImputer())]),\n",
       "                                                                         [&#x27;Age&#x27;])])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        LogisticRegression(fit_intercept=False))]),\n",
       "             param_grid={&#x27;classifier__C&#x27;: [0.001, 0.1, 0.2, 0.5, 1, 1.1, 1.2,\n",
       "                                           1.3, 1.4, 1.5, 1.6, 2, 3, 4, 5, 6, 7,\n",
       "                                           8, 9, 10, 100, 1000],\n",
       "                         &#x27;classifier__fit_intercept&#x27;: [False]},\n",
       "             return_train_score=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;categorical_features_wo_nan&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False),\n",
       "                                                  [&#x27;Pclass&#x27;, &#x27;Sex&#x27;, &#x27;Embarked&#x27;,\n",
       "                                                   &#x27;CabinCat&#x27;]),\n",
       "                                                 (&#x27;numerical_features_w_nan&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer())]),\n",
       "                                                  [&#x27;Age&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression(fit_intercept=False))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;categorical_features_wo_nan&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse_output=False),\n",
       "                                 [&#x27;Pclass&#x27;, &#x27;Sex&#x27;, &#x27;Embarked&#x27;, &#x27;CabinCat&#x27;]),\n",
       "                                (&#x27;numerical_features_w_nan&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer())]),\n",
       "                                 [&#x27;Age&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical_features_wo_nan</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Pclass&#x27;, &#x27;Sex&#x27;, &#x27;Embarked&#x27;, &#x27;CabinCat&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical_features_w_nan</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Age&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(fit_intercept=False)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('preprocessing',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('categorical_features_wo_nan',\n",
       "                                                                         OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                       sparse_output=False),\n",
       "                                                                         ['Pclass',\n",
       "                                                                          'Sex',\n",
       "                                                                          'Embarked',\n",
       "                                                                          'CabinCat']),\n",
       "                                                                        ('numerical_features_w_nan',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer())]),\n",
       "                                                                         ['Age'])])),\n",
       "                                       ('classifier',\n",
       "                                        LogisticRegression(fit_intercept=False))]),\n",
       "             param_grid={'classifier__C': [0.001, 0.1, 0.2, 0.5, 1, 1.1, 1.2,\n",
       "                                           1.3, 1.4, 1.5, 1.6, 2, 3, 4, 5, 6, 7,\n",
       "                                           8, 9, 10, 100, 1000],\n",
       "                         'classifier__fit_intercept': [False]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"grid_search.fit(X, y)\";\n",
       "                var nbb_formatted_code = \"grid_search.fit(X, y)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10e1d1a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__C</th>\n",
       "      <th>param_classifier__fit_intercept</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023432</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>0.007818</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "      <td>{'classifier__C': 0.001, 'classifier__fit_inte...</td>\n",
       "      <td>0.620112</td>\n",
       "      <td>0.612360</td>\n",
       "      <td>0.623596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618404</td>\n",
       "      <td>0.005097</td>\n",
       "      <td>22</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.618513</td>\n",
       "      <td>0.615708</td>\n",
       "      <td>0.615708</td>\n",
       "      <td>0.618513</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>0.001301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023018</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>0.010216</td>\n",
       "      <td>0.006650</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__fit_interc...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796855</td>\n",
       "      <td>0.016070</td>\n",
       "      <td>14</td>\n",
       "      <td>0.811798</td>\n",
       "      <td>0.820477</td>\n",
       "      <td>0.816269</td>\n",
       "      <td>0.805049</td>\n",
       "      <td>0.805049</td>\n",
       "      <td>0.811728</td>\n",
       "      <td>0.006106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.032645</td>\n",
       "      <td>0.008438</td>\n",
       "      <td>0.013310</td>\n",
       "      <td>0.007797</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>{'classifier__C': 0.2, 'classifier__fit_interc...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799096</td>\n",
       "      <td>0.017968</td>\n",
       "      <td>9</td>\n",
       "      <td>0.818820</td>\n",
       "      <td>0.824684</td>\n",
       "      <td>0.813464</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.805049</td>\n",
       "      <td>0.813694</td>\n",
       "      <td>0.007407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.056861</td>\n",
       "      <td>0.033233</td>\n",
       "      <td>0.008583</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>{'classifier__C': 0.5, 'classifier__fit_interc...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801356</td>\n",
       "      <td>0.016003</td>\n",
       "      <td>1</td>\n",
       "      <td>0.813202</td>\n",
       "      <td>0.824684</td>\n",
       "      <td>0.817672</td>\n",
       "      <td>0.814867</td>\n",
       "      <td>0.812062</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.004508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041501</td>\n",
       "      <td>0.010407</td>\n",
       "      <td>0.008204</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__fit_intercep...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801356</td>\n",
       "      <td>0.012951</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.821879</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.819074</td>\n",
       "      <td>0.809257</td>\n",
       "      <td>0.817057</td>\n",
       "      <td>0.006853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.040746</td>\n",
       "      <td>0.013710</td>\n",
       "      <td>0.010899</td>\n",
       "      <td>0.007198</td>\n",
       "      <td>1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>{'classifier__C': 1.1, 'classifier__fit_interc...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799109</td>\n",
       "      <td>0.013839</td>\n",
       "      <td>5</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.821879</td>\n",
       "      <td>0.824684</td>\n",
       "      <td>0.819074</td>\n",
       "      <td>0.813464</td>\n",
       "      <td>0.817618</td>\n",
       "      <td>0.005691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.074257</td>\n",
       "      <td>0.041819</td>\n",
       "      <td>0.013516</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>{'classifier__C': 1.2, 'classifier__fit_interc...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797985</td>\n",
       "      <td>0.014128</td>\n",
       "      <td>10</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.821879</td>\n",
       "      <td>0.824684</td>\n",
       "      <td>0.820477</td>\n",
       "      <td>0.814867</td>\n",
       "      <td>0.818179</td>\n",
       "      <td>0.005599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.040473</td>\n",
       "      <td>0.008164</td>\n",
       "      <td>0.014660</td>\n",
       "      <td>0.008732</td>\n",
       "      <td>1.3</td>\n",
       "      <td>False</td>\n",
       "      <td>{'classifier__C': 1.3, 'classifier__fit_interc...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800232</td>\n",
       "      <td>0.012971</td>\n",
       "      <td>3</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.823282</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.820477</td>\n",
       "      <td>0.812062</td>\n",
       "      <td>0.818179</td>\n",
       "      <td>0.006569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.039534</td>\n",
       "      <td>0.015328</td>\n",
       "      <td>0.015991</td>\n",
       "      <td>0.012289</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "      <td>{'classifier__C': 1.4, 'classifier__fit_interc...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797979</td>\n",
       "      <td>0.011793</td>\n",
       "      <td>11</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.821879</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.820477</td>\n",
       "      <td>0.810659</td>\n",
       "      <td>0.817618</td>\n",
       "      <td>0.006647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.061271</td>\n",
       "      <td>0.018972</td>\n",
       "      <td>0.008720</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>{'classifier__C': 1.5, 'classifier__fit_interc...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799102</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>6</td>\n",
       "      <td>0.810393</td>\n",
       "      <td>0.823282</td>\n",
       "      <td>0.823282</td>\n",
       "      <td>0.820477</td>\n",
       "      <td>0.813464</td>\n",
       "      <td>0.818180</td>\n",
       "      <td>0.005295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.035588</td>\n",
       "      <td>0.016675</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.007683</td>\n",
       "      <td>1.6</td>\n",
       "      <td>False</td>\n",
       "      <td>{'classifier__C': 1.6, 'classifier__fit_interc...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800226</td>\n",
       "      <td>0.011533</td>\n",
       "      <td>4</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.820477</td>\n",
       "      <td>0.824684</td>\n",
       "      <td>0.817672</td>\n",
       "      <td>0.813464</td>\n",
       "      <td>0.817057</td>\n",
       "      <td>0.005445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.049072</td>\n",
       "      <td>0.019422</td>\n",
       "      <td>0.010645</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>{'classifier__C': 2, 'classifier__fit_intercep...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799102</td>\n",
       "      <td>0.012995</td>\n",
       "      <td>7</td>\n",
       "      <td>0.811798</td>\n",
       "      <td>0.823282</td>\n",
       "      <td>0.827489</td>\n",
       "      <td>0.821879</td>\n",
       "      <td>0.812062</td>\n",
       "      <td>0.819302</td>\n",
       "      <td>0.006297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.049351</td>\n",
       "      <td>0.022807</td>\n",
       "      <td>0.012846</td>\n",
       "      <td>0.009650</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>{'classifier__C': 3, 'classifier__fit_intercep...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797979</td>\n",
       "      <td>0.009412</td>\n",
       "      <td>11</td>\n",
       "      <td>0.811798</td>\n",
       "      <td>0.823282</td>\n",
       "      <td>0.827489</td>\n",
       "      <td>0.820477</td>\n",
       "      <td>0.809257</td>\n",
       "      <td>0.818461</td>\n",
       "      <td>0.006898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.042768</td>\n",
       "      <td>0.020146</td>\n",
       "      <td>0.007781</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>{'classifier__C': 4, 'classifier__fit_intercep...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795732</td>\n",
       "      <td>0.011064</td>\n",
       "      <td>17</td>\n",
       "      <td>0.811798</td>\n",
       "      <td>0.823282</td>\n",
       "      <td>0.819074</td>\n",
       "      <td>0.820477</td>\n",
       "      <td>0.812062</td>\n",
       "      <td>0.817339</td>\n",
       "      <td>0.004620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.027726</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>{'classifier__C': 5, 'classifier__fit_intercep...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796855</td>\n",
       "      <td>0.009702</td>\n",
       "      <td>14</td>\n",
       "      <td>0.811798</td>\n",
       "      <td>0.823282</td>\n",
       "      <td>0.821879</td>\n",
       "      <td>0.820477</td>\n",
       "      <td>0.810659</td>\n",
       "      <td>0.817619</td>\n",
       "      <td>0.005305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.071885</td>\n",
       "      <td>0.026766</td>\n",
       "      <td>0.011883</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>{'classifier__C': 6, 'classifier__fit_intercep...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.794608</td>\n",
       "      <td>0.008510</td>\n",
       "      <td>21</td>\n",
       "      <td>0.811798</td>\n",
       "      <td>0.823282</td>\n",
       "      <td>0.819074</td>\n",
       "      <td>0.819074</td>\n",
       "      <td>0.809257</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.005174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.039566</td>\n",
       "      <td>0.006743</td>\n",
       "      <td>0.008662</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>{'classifier__C': 7, 'classifier__fit_intercep...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796855</td>\n",
       "      <td>0.012540</td>\n",
       "      <td>14</td>\n",
       "      <td>0.810393</td>\n",
       "      <td>0.821879</td>\n",
       "      <td>0.823282</td>\n",
       "      <td>0.819074</td>\n",
       "      <td>0.807854</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.006223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.033064</td>\n",
       "      <td>0.008669</td>\n",
       "      <td>0.012936</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>{'classifier__C': 8, 'classifier__fit_intercep...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799102</td>\n",
       "      <td>0.012995</td>\n",
       "      <td>7</td>\n",
       "      <td>0.810393</td>\n",
       "      <td>0.823282</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.821879</td>\n",
       "      <td>0.809257</td>\n",
       "      <td>0.818180</td>\n",
       "      <td>0.006964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.088103</td>\n",
       "      <td>0.081406</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>{'classifier__C': 9, 'classifier__fit_intercep...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795732</td>\n",
       "      <td>0.011064</td>\n",
       "      <td>17</td>\n",
       "      <td>0.811798</td>\n",
       "      <td>0.823282</td>\n",
       "      <td>0.824684</td>\n",
       "      <td>0.820477</td>\n",
       "      <td>0.813464</td>\n",
       "      <td>0.818741</td>\n",
       "      <td>0.005196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.038157</td>\n",
       "      <td>0.018676</td>\n",
       "      <td>0.011550</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>{'classifier__C': 10, 'classifier__fit_interce...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.794614</td>\n",
       "      <td>0.010380</td>\n",
       "      <td>19</td>\n",
       "      <td>0.811798</td>\n",
       "      <td>0.823282</td>\n",
       "      <td>0.824684</td>\n",
       "      <td>0.820477</td>\n",
       "      <td>0.807854</td>\n",
       "      <td>0.817619</td>\n",
       "      <td>0.006624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.068016</td>\n",
       "      <td>0.044219</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>{'classifier__C': 100, 'classifier__fit_interc...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796861</td>\n",
       "      <td>0.011918</td>\n",
       "      <td>13</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.823282</td>\n",
       "      <td>0.823282</td>\n",
       "      <td>0.821879</td>\n",
       "      <td>0.813464</td>\n",
       "      <td>0.818179</td>\n",
       "      <td>0.005873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.035383</td>\n",
       "      <td>0.007499</td>\n",
       "      <td>0.009388</td>\n",
       "      <td>0.003043</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>{'classifier__C': 1000, 'classifier__fit_inter...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.794614</td>\n",
       "      <td>0.010380</td>\n",
       "      <td>20</td>\n",
       "      <td>0.811798</td>\n",
       "      <td>0.824684</td>\n",
       "      <td>0.823282</td>\n",
       "      <td>0.819074</td>\n",
       "      <td>0.807854</td>\n",
       "      <td>0.817339</td>\n",
       "      <td>0.006526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.023432      0.010684         0.007818        0.001402   \n",
       "1        0.023018      0.002659         0.010216        0.006650   \n",
       "2        0.032645      0.008438         0.013310        0.007797   \n",
       "3        0.056861      0.033233         0.008583        0.001173   \n",
       "4        0.041501      0.010407         0.008204        0.000278   \n",
       "5        0.040746      0.013710         0.010899        0.007198   \n",
       "6        0.074257      0.041819         0.013516        0.007595   \n",
       "7        0.040473      0.008164         0.014660        0.008732   \n",
       "8        0.039534      0.015328         0.015991        0.012289   \n",
       "9        0.061271      0.018972         0.008720        0.000915   \n",
       "10       0.035588      0.016675         0.014006        0.007683   \n",
       "11       0.049072      0.019422         0.010645        0.002054   \n",
       "12       0.049351      0.022807         0.012846        0.009650   \n",
       "13       0.042768      0.020146         0.007781        0.000305   \n",
       "14       0.027726      0.002915         0.007380        0.000717   \n",
       "15       0.071885      0.026766         0.011883        0.003540   \n",
       "16       0.039566      0.006743         0.008662        0.001105   \n",
       "17       0.033064      0.008669         0.012936        0.009781   \n",
       "18       0.088103      0.081406         0.013575        0.005277   \n",
       "19       0.038157      0.018676         0.011550        0.006029   \n",
       "20       0.068016      0.044219         0.015656        0.004472   \n",
       "21       0.035383      0.007499         0.009388        0.003043   \n",
       "\n",
       "   param_classifier__C param_classifier__fit_intercept  \\\n",
       "0                0.001                           False   \n",
       "1                  0.1                           False   \n",
       "2                  0.2                           False   \n",
       "3                  0.5                           False   \n",
       "4                    1                           False   \n",
       "5                  1.1                           False   \n",
       "6                  1.2                           False   \n",
       "7                  1.3                           False   \n",
       "8                  1.4                           False   \n",
       "9                  1.5                           False   \n",
       "10                 1.6                           False   \n",
       "11                   2                           False   \n",
       "12                   3                           False   \n",
       "13                   4                           False   \n",
       "14                   5                           False   \n",
       "15                   6                           False   \n",
       "16                   7                           False   \n",
       "17                   8                           False   \n",
       "18                   9                           False   \n",
       "19                  10                           False   \n",
       "20                 100                           False   \n",
       "21                1000                           False   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'classifier__C': 0.001, 'classifier__fit_inte...           0.620112   \n",
       "1   {'classifier__C': 0.1, 'classifier__fit_interc...           0.798883   \n",
       "2   {'classifier__C': 0.2, 'classifier__fit_interc...           0.804469   \n",
       "3   {'classifier__C': 0.5, 'classifier__fit_interc...           0.793296   \n",
       "4   {'classifier__C': 1, 'classifier__fit_intercep...           0.793296   \n",
       "5   {'classifier__C': 1.1, 'classifier__fit_interc...           0.793296   \n",
       "6   {'classifier__C': 1.2, 'classifier__fit_interc...           0.793296   \n",
       "7   {'classifier__C': 1.3, 'classifier__fit_interc...           0.793296   \n",
       "8   {'classifier__C': 1.4, 'classifier__fit_interc...           0.798883   \n",
       "9   {'classifier__C': 1.5, 'classifier__fit_interc...           0.798883   \n",
       "10  {'classifier__C': 1.6, 'classifier__fit_interc...           0.798883   \n",
       "11  {'classifier__C': 2, 'classifier__fit_intercep...           0.798883   \n",
       "12  {'classifier__C': 3, 'classifier__fit_intercep...           0.798883   \n",
       "13  {'classifier__C': 4, 'classifier__fit_intercep...           0.798883   \n",
       "14  {'classifier__C': 5, 'classifier__fit_intercep...           0.798883   \n",
       "15  {'classifier__C': 6, 'classifier__fit_intercep...           0.798883   \n",
       "16  {'classifier__C': 7, 'classifier__fit_intercep...           0.798883   \n",
       "17  {'classifier__C': 8, 'classifier__fit_intercep...           0.798883   \n",
       "18  {'classifier__C': 9, 'classifier__fit_intercep...           0.798883   \n",
       "19  {'classifier__C': 10, 'classifier__fit_interce...           0.793296   \n",
       "20  {'classifier__C': 100, 'classifier__fit_interc...           0.793296   \n",
       "21  {'classifier__C': 1000, 'classifier__fit_inter...           0.793296   \n",
       "\n",
       "    split1_test_score  split2_test_score  ...  mean_test_score  \\\n",
       "0            0.612360           0.623596  ...         0.618404   \n",
       "1            0.797753           0.797753  ...         0.796855   \n",
       "2            0.797753           0.797753  ...         0.799096   \n",
       "3            0.792135           0.803371  ...         0.801356   \n",
       "4            0.792135           0.803371  ...         0.801356   \n",
       "5            0.792135           0.797753  ...         0.799109   \n",
       "6            0.792135           0.792135  ...         0.797985   \n",
       "7            0.792135           0.797753  ...         0.800232   \n",
       "8            0.792135           0.792135  ...         0.797979   \n",
       "9            0.792135           0.797753  ...         0.799102   \n",
       "10           0.792135           0.803371  ...         0.800226   \n",
       "11           0.792135           0.803371  ...         0.799102   \n",
       "12           0.792135           0.797753  ...         0.797979   \n",
       "13           0.792135           0.792135  ...         0.795732   \n",
       "14           0.792135           0.792135  ...         0.796855   \n",
       "15           0.792135           0.786517  ...         0.794608   \n",
       "16           0.792135           0.786517  ...         0.796855   \n",
       "17           0.792135           0.803371  ...         0.799102   \n",
       "18           0.792135           0.792135  ...         0.795732   \n",
       "19           0.792135           0.786517  ...         0.794614   \n",
       "20           0.792135           0.792135  ...         0.796861   \n",
       "21           0.786517           0.792135  ...         0.794614   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         0.005097               22            0.617978            0.618513   \n",
       "1         0.016070               14            0.811798            0.820477   \n",
       "2         0.017968                9            0.818820            0.824684   \n",
       "3         0.016003                1            0.813202            0.824684   \n",
       "4         0.012951                1            0.808989            0.821879   \n",
       "5         0.013839                5            0.808989            0.821879   \n",
       "6         0.014128               10            0.808989            0.821879   \n",
       "7         0.012971                3            0.808989            0.823282   \n",
       "8         0.011793               11            0.808989            0.821879   \n",
       "9         0.011445                6            0.810393            0.823282   \n",
       "10        0.011533                4            0.808989            0.820477   \n",
       "11        0.012995                7            0.811798            0.823282   \n",
       "12        0.009412               11            0.811798            0.823282   \n",
       "13        0.011064               17            0.811798            0.823282   \n",
       "14        0.009702               14            0.811798            0.823282   \n",
       "15        0.008510               21            0.811798            0.823282   \n",
       "16        0.012540               14            0.810393            0.821879   \n",
       "17        0.012995                7            0.810393            0.823282   \n",
       "18        0.011064               17            0.811798            0.823282   \n",
       "19        0.010380               19            0.811798            0.823282   \n",
       "20        0.011918               13            0.808989            0.823282   \n",
       "21        0.010380               20            0.811798            0.824684   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             0.615708            0.615708            0.618513   \n",
       "1             0.816269            0.805049            0.805049   \n",
       "2             0.813464            0.806452            0.805049   \n",
       "3             0.817672            0.814867            0.812062   \n",
       "4             0.826087            0.819074            0.809257   \n",
       "5             0.824684            0.819074            0.813464   \n",
       "6             0.824684            0.820477            0.814867   \n",
       "7             0.826087            0.820477            0.812062   \n",
       "8             0.826087            0.820477            0.810659   \n",
       "9             0.823282            0.820477            0.813464   \n",
       "10            0.824684            0.817672            0.813464   \n",
       "11            0.827489            0.821879            0.812062   \n",
       "12            0.827489            0.820477            0.809257   \n",
       "13            0.819074            0.820477            0.812062   \n",
       "14            0.821879            0.820477            0.810659   \n",
       "15            0.819074            0.819074            0.809257   \n",
       "16            0.823282            0.819074            0.807854   \n",
       "17            0.826087            0.821879            0.809257   \n",
       "18            0.824684            0.820477            0.813464   \n",
       "19            0.824684            0.820477            0.807854   \n",
       "20            0.823282            0.821879            0.813464   \n",
       "21            0.823282            0.819074            0.807854   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0           0.617284         0.001301  \n",
       "1           0.811728         0.006106  \n",
       "2           0.813694         0.007407  \n",
       "3           0.816497         0.004508  \n",
       "4           0.817057         0.006853  \n",
       "5           0.817618         0.005691  \n",
       "6           0.818179         0.005599  \n",
       "7           0.818179         0.006569  \n",
       "8           0.817618         0.006647  \n",
       "9           0.818180         0.005295  \n",
       "10          0.817057         0.005445  \n",
       "11          0.819302         0.006297  \n",
       "12          0.818461         0.006898  \n",
       "13          0.817339         0.004620  \n",
       "14          0.817619         0.005305  \n",
       "15          0.816497         0.005174  \n",
       "16          0.816497         0.006223  \n",
       "17          0.818180         0.006964  \n",
       "18          0.818741         0.005196  \n",
       "19          0.817619         0.006624  \n",
       "20          0.818179         0.005873  \n",
       "21          0.817339         0.006526  \n",
       "\n",
       "[22 rows x 22 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"pd.DataFrame(grid_search.cv_results_)\";\n",
       "                var nbb_formatted_code = \"pd.DataFrame(grid_search.cv_results_)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bffa88cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.11651034,  0.69121408, -0.40844652,  1.98443979, -0.58516189,\n",
       "         0.66465723,  0.49527933,  0.15284235,  0.08649899,  0.13085689,\n",
       "         0.33989409, -0.09199886,  0.5444967 ,  0.86483199,  0.37754538,\n",
       "        -0.21288019, -0.08767163, -0.46579647, -0.03348929, -0.26217552,\n",
       "        -0.06106408]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"grid_search.best_estimator_[-1].coef_\";\n",
       "                var nbb_formatted_code = \"grid_search.best_estimator_[-1].coef_\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_search.best_estimator_[-1].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa8595c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categorical_features_wo_nan__Pclass_1</th>\n",
       "      <th>categorical_features_wo_nan__Pclass_2</th>\n",
       "      <th>categorical_features_wo_nan__Pclass_3</th>\n",
       "      <th>categorical_features_wo_nan__Sex_female</th>\n",
       "      <th>categorical_features_wo_nan__Sex_male</th>\n",
       "      <th>categorical_features_wo_nan__Embarked_C</th>\n",
       "      <th>categorical_features_wo_nan__Embarked_Q</th>\n",
       "      <th>categorical_features_wo_nan__Embarked_S</th>\n",
       "      <th>categorical_features_wo_nan__Embarked_unknown</th>\n",
       "      <th>categorical_features_wo_nan__CabinCat_A</th>\n",
       "      <th>...</th>\n",
       "      <th>categorical_features_wo_nan__CabinCat_C</th>\n",
       "      <th>categorical_features_wo_nan__CabinCat_D</th>\n",
       "      <th>categorical_features_wo_nan__CabinCat_E</th>\n",
       "      <th>categorical_features_wo_nan__CabinCat_F</th>\n",
       "      <th>categorical_features_wo_nan__CabinCat_G</th>\n",
       "      <th>categorical_features_wo_nan__CabinCat_T</th>\n",
       "      <th>categorical_features_wo_nan__CabinCat_n</th>\n",
       "      <th>numerical_features_w_nan__Age</th>\n",
       "      <th>remainder__SibSp</th>\n",
       "      <th>remainder__Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     categorical_features_wo_nan__Pclass_1  \\\n",
       "0                                      0.0   \n",
       "1                                      1.0   \n",
       "2                                      0.0   \n",
       "3                                      1.0   \n",
       "4                                      0.0   \n",
       "..                                     ...   \n",
       "886                                    0.0   \n",
       "887                                    1.0   \n",
       "888                                    0.0   \n",
       "889                                    1.0   \n",
       "890                                    0.0   \n",
       "\n",
       "     categorical_features_wo_nan__Pclass_2  \\\n",
       "0                                      0.0   \n",
       "1                                      0.0   \n",
       "2                                      0.0   \n",
       "3                                      0.0   \n",
       "4                                      0.0   \n",
       "..                                     ...   \n",
       "886                                    1.0   \n",
       "887                                    0.0   \n",
       "888                                    0.0   \n",
       "889                                    0.0   \n",
       "890                                    0.0   \n",
       "\n",
       "     categorical_features_wo_nan__Pclass_3  \\\n",
       "0                                      1.0   \n",
       "1                                      0.0   \n",
       "2                                      1.0   \n",
       "3                                      0.0   \n",
       "4                                      1.0   \n",
       "..                                     ...   \n",
       "886                                    0.0   \n",
       "887                                    0.0   \n",
       "888                                    1.0   \n",
       "889                                    0.0   \n",
       "890                                    1.0   \n",
       "\n",
       "     categorical_features_wo_nan__Sex_female  \\\n",
       "0                                        0.0   \n",
       "1                                        1.0   \n",
       "2                                        1.0   \n",
       "3                                        1.0   \n",
       "4                                        0.0   \n",
       "..                                       ...   \n",
       "886                                      0.0   \n",
       "887                                      1.0   \n",
       "888                                      1.0   \n",
       "889                                      0.0   \n",
       "890                                      0.0   \n",
       "\n",
       "     categorical_features_wo_nan__Sex_male  \\\n",
       "0                                      1.0   \n",
       "1                                      0.0   \n",
       "2                                      0.0   \n",
       "3                                      0.0   \n",
       "4                                      1.0   \n",
       "..                                     ...   \n",
       "886                                    1.0   \n",
       "887                                    0.0   \n",
       "888                                    0.0   \n",
       "889                                    1.0   \n",
       "890                                    1.0   \n",
       "\n",
       "     categorical_features_wo_nan__Embarked_C  \\\n",
       "0                                        0.0   \n",
       "1                                        1.0   \n",
       "2                                        0.0   \n",
       "3                                        0.0   \n",
       "4                                        0.0   \n",
       "..                                       ...   \n",
       "886                                      0.0   \n",
       "887                                      0.0   \n",
       "888                                      0.0   \n",
       "889                                      1.0   \n",
       "890                                      0.0   \n",
       "\n",
       "     categorical_features_wo_nan__Embarked_Q  \\\n",
       "0                                        0.0   \n",
       "1                                        0.0   \n",
       "2                                        0.0   \n",
       "3                                        0.0   \n",
       "4                                        0.0   \n",
       "..                                       ...   \n",
       "886                                      0.0   \n",
       "887                                      0.0   \n",
       "888                                      0.0   \n",
       "889                                      0.0   \n",
       "890                                      1.0   \n",
       "\n",
       "     categorical_features_wo_nan__Embarked_S  \\\n",
       "0                                        1.0   \n",
       "1                                        0.0   \n",
       "2                                        1.0   \n",
       "3                                        1.0   \n",
       "4                                        1.0   \n",
       "..                                       ...   \n",
       "886                                      1.0   \n",
       "887                                      1.0   \n",
       "888                                      1.0   \n",
       "889                                      0.0   \n",
       "890                                      0.0   \n",
       "\n",
       "     categorical_features_wo_nan__Embarked_unknown  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                              0.0   \n",
       "3                                              0.0   \n",
       "4                                              0.0   \n",
       "..                                             ...   \n",
       "886                                            0.0   \n",
       "887                                            0.0   \n",
       "888                                            0.0   \n",
       "889                                            0.0   \n",
       "890                                            0.0   \n",
       "\n",
       "     categorical_features_wo_nan__CabinCat_A  ...  \\\n",
       "0                                        0.0  ...   \n",
       "1                                        0.0  ...   \n",
       "2                                        0.0  ...   \n",
       "3                                        0.0  ...   \n",
       "4                                        0.0  ...   \n",
       "..                                       ...  ...   \n",
       "886                                      0.0  ...   \n",
       "887                                      0.0  ...   \n",
       "888                                      0.0  ...   \n",
       "889                                      0.0  ...   \n",
       "890                                      0.0  ...   \n",
       "\n",
       "     categorical_features_wo_nan__CabinCat_C  \\\n",
       "0                                        0.0   \n",
       "1                                        1.0   \n",
       "2                                        0.0   \n",
       "3                                        1.0   \n",
       "4                                        0.0   \n",
       "..                                       ...   \n",
       "886                                      0.0   \n",
       "887                                      0.0   \n",
       "888                                      0.0   \n",
       "889                                      1.0   \n",
       "890                                      0.0   \n",
       "\n",
       "     categorical_features_wo_nan__CabinCat_D  \\\n",
       "0                                        0.0   \n",
       "1                                        0.0   \n",
       "2                                        0.0   \n",
       "3                                        0.0   \n",
       "4                                        0.0   \n",
       "..                                       ...   \n",
       "886                                      0.0   \n",
       "887                                      0.0   \n",
       "888                                      0.0   \n",
       "889                                      0.0   \n",
       "890                                      0.0   \n",
       "\n",
       "     categorical_features_wo_nan__CabinCat_E  \\\n",
       "0                                        0.0   \n",
       "1                                        0.0   \n",
       "2                                        0.0   \n",
       "3                                        0.0   \n",
       "4                                        0.0   \n",
       "..                                       ...   \n",
       "886                                      0.0   \n",
       "887                                      0.0   \n",
       "888                                      0.0   \n",
       "889                                      0.0   \n",
       "890                                      0.0   \n",
       "\n",
       "     categorical_features_wo_nan__CabinCat_F  \\\n",
       "0                                        0.0   \n",
       "1                                        0.0   \n",
       "2                                        0.0   \n",
       "3                                        0.0   \n",
       "4                                        0.0   \n",
       "..                                       ...   \n",
       "886                                      0.0   \n",
       "887                                      0.0   \n",
       "888                                      0.0   \n",
       "889                                      0.0   \n",
       "890                                      0.0   \n",
       "\n",
       "     categorical_features_wo_nan__CabinCat_G  \\\n",
       "0                                        0.0   \n",
       "1                                        0.0   \n",
       "2                                        0.0   \n",
       "3                                        0.0   \n",
       "4                                        0.0   \n",
       "..                                       ...   \n",
       "886                                      0.0   \n",
       "887                                      0.0   \n",
       "888                                      0.0   \n",
       "889                                      0.0   \n",
       "890                                      0.0   \n",
       "\n",
       "     categorical_features_wo_nan__CabinCat_T  \\\n",
       "0                                        0.0   \n",
       "1                                        0.0   \n",
       "2                                        0.0   \n",
       "3                                        0.0   \n",
       "4                                        0.0   \n",
       "..                                       ...   \n",
       "886                                      0.0   \n",
       "887                                      0.0   \n",
       "888                                      0.0   \n",
       "889                                      0.0   \n",
       "890                                      0.0   \n",
       "\n",
       "     categorical_features_wo_nan__CabinCat_n  numerical_features_w_nan__Age  \\\n",
       "0                                        1.0                      22.000000   \n",
       "1                                        0.0                      38.000000   \n",
       "2                                        1.0                      26.000000   \n",
       "3                                        0.0                      35.000000   \n",
       "4                                        1.0                      35.000000   \n",
       "..                                       ...                            ...   \n",
       "886                                      1.0                      27.000000   \n",
       "887                                      0.0                      19.000000   \n",
       "888                                      1.0                      29.699118   \n",
       "889                                      0.0                      26.000000   \n",
       "890                                      1.0                      32.000000   \n",
       "\n",
       "     remainder__SibSp  remainder__Parch  \n",
       "0                   1                 0  \n",
       "1                   1                 0  \n",
       "2                   0                 0  \n",
       "3                   1                 0  \n",
       "4                   0                 0  \n",
       "..                ...               ...  \n",
       "886                 0                 0  \n",
       "887                 0                 0  \n",
       "888                 1                 2  \n",
       "889                 0                 0  \n",
       "890                 0                 0  \n",
       "\n",
       "[891 rows x 21 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"preprocessor.fit_transform(X)\";\n",
       "                var nbb_formatted_code = \"preprocessor.fit_transform(X)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b9e9c2",
   "metadata": {},
   "source": [
    "___\n",
    "# Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eba1c154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"def callback(intermediate_result):\\n    print(f\\\"fun={intermediate_result.fun}\\\")\";\n",
       "                var nbb_formatted_code = \"def callback(intermediate_result):\\n    print(f\\\"fun={intermediate_result.fun}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def callback(intermediate_result):\n",
    "    print(f\"fun={intermediate_result.fun}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "795cacd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fun=416.015700488111\n",
      "fun=415.7457521852242\n",
      "fun=415.7028985462279\n",
      "fun=415.70233681909383\n",
      "fun=415.70095393097137\n",
      "fun=415.7002621046415\n",
      "fun=415.6994301589399\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"res = minimize(\\n    func_with_bias,\\n    np.array([0.0]),\\n    args=(\\n        preprocessor.fit_transform(X).to_numpy(),\\n        y.to_numpy(),\\n    ),\\n    method=\\\"L-BFGS-B\\\",\\n    jac=jac_func_with_bias,\\n    callback=callback,\\n)\";\n",
       "                var nbb_formatted_code = \"res = minimize(\\n    func_with_bias,\\n    np.array([0.0]),\\n    args=(\\n        preprocessor.fit_transform(X).to_numpy(),\\n        y.to_numpy(),\\n    ),\\n    method=\\\"L-BFGS-B\\\",\\n    jac=jac_func_with_bias,\\n    callback=callback,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = minimize(\n",
    "    func_with_bias,\n",
    "    np.array([0.0]),\n",
    "    args=(\n",
    "        preprocessor.fit_transform(X).to_numpy(),\n",
    "        y.to_numpy(),\n",
    "    ),\n",
    "    method=\"L-BFGS-B\",\n",
    "    jac=jac_func_with_bias,\n",
    "    callback=callback,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f4076e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: ABNORMAL_TERMINATION_IN_LNSRCH\n",
       "  success: False\n",
       "   status: 2\n",
       "      fun: 415.7002601196556\n",
       "        x: [-3.364e-01]\n",
       "      nit: 7\n",
       "      jac: [ 7.452e-05]\n",
       "     nfev: 64\n",
       "     njev: 64\n",
       " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"res\";\n",
       "                var nbb_formatted_code = \"res\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f60875b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.39996636])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"1/np.exp(res.x)\";\n",
       "                var nbb_formatted_code = \"1 / np.exp(res.x)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1 / np.exp(res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cc7c7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"X1 = preprocessor.fit_transform(X).to_numpy()\\ny1 = y.to_numpy()\";\n",
       "                var nbb_formatted_code = \"X1 = preprocessor.fit_transform(X).to_numpy()\\ny1 = y.to_numpy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X1 = preprocessor.fit_transform(X).to_numpy()\n",
    "y1 = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "def9650b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fun=917.3936949762424\n",
      "fun=909.2815416894933\n",
      "fun=908.7238866764843\n",
      "fun=908.5830502425201\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 182;\n",
       "                var nbb_unformatted_code = \"res = minimize(\\n    func_with_bias,\\n    np.array([0.0]),\\n    args=(\\n        X1,\\n        y1,\\n    ),\\n    method=\\\"L-BFGS-B\\\",\\n    jac=jac_func_with_bias,\\n    callback=callback,\\n)\";\n",
       "                var nbb_formatted_code = \"res = minimize(\\n    func_with_bias,\\n    np.array([0.0]),\\n    args=(\\n        X1,\\n        y1,\\n    ),\\n    method=\\\"L-BFGS-B\\\",\\n    jac=jac_func_with_bias,\\n    callback=callback,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = minimize(\n",
    "    func_with_bias,\n",
    "    np.array([0.0]),\n",
    "    args=(\n",
    "        X1,\n",
    "        y1,\n",
    "    ),\n",
    "    method=\"L-BFGS-B\",\n",
    "    jac=jac_func_with_bias,\n",
    "    callback=callback,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c404cc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 908.5830502425201\n",
       "        x: [-3.176e+00]\n",
       "      nit: 4\n",
       "      jac: [ 6.802e-06]\n",
       "     nfev: 8\n",
       "     njev: 8\n",
       " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 183;\n",
       "                var nbb_unformatted_code = \"res\";\n",
       "                var nbb_formatted_code = \"res\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7db450de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04176261])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 184;\n",
       "                var nbb_unformatted_code = \"np.exp(res.x)\";\n",
       "                var nbb_formatted_code = \"np.exp(res.x)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.exp(res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2e5c6bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesianRidge(alpha_1=1000000.0, alpha_2=1000000.0, fit_intercept=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BayesianRidge</label><div class=\"sk-toggleable__content\"><pre>BayesianRidge(alpha_1=1000000.0, alpha_2=1000000.0, fit_intercept=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesianRidge(alpha_1=1000000.0, alpha_2=1000000.0, fit_intercept=False)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 185;\n",
       "                var nbb_unformatted_code = \"model = BayesianRidge(\\n    alpha_1=1 / 1 * 1e6,\\n    alpha_2=1e6,\\n    lambda_1=1e-6,\\n    lambda_2=1e-6,\\n    fit_intercept=False,\\n)\\nmodel.fit(X1, y1)\";\n",
       "                var nbb_formatted_code = \"model = BayesianRidge(\\n    alpha_1=1 / 1 * 1e6,\\n    alpha_2=1e6,\\n    lambda_1=1e-6,\\n    lambda_2=1e-6,\\n    fit_intercept=False,\\n)\\nmodel.fit(X1, y1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BayesianRidge(\n",
    "    alpha_1=1 / 1 * 1e6,\n",
    "    alpha_2=1e6,\n",
    "    lambda_1=1e-6,\n",
    "    lambda_2=1e-6,\n",
    "    fit_intercept=False,\n",
    ")\n",
    "model.fit(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "0d915f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.189134422067746"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 191;\n",
       "                var nbb_unformatted_code = \"np.log(1 / model.lambda_)\";\n",
       "                var nbb_formatted_code = \"np.log(1 / model.lambda_)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.log(1 / model.lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54a8bcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481.2375065318942\n",
      "447.80239593850894\n",
      "426.7367949669429\n",
      "417.1934379524614\n",
      "416.017499735816\n",
      "419.8408348902286\n",
      "426.16091279686424\n",
      "433.5910798852872\n",
      "441.47220323542643\n",
      "449.58914179809045\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"for log_sigma2 in [\\n    -4,\\n    -3,-2,-1,0,1,2,3,4,5,\\n]:\\n    print(\\n        func_with_bias(\\n            np.array([log_sigma2]),\\n            X1,\\n            y1,\\n        )\\n    )\";\n",
       "                var nbb_formatted_code = \"for log_sigma2 in [\\n    -4,\\n    -3,\\n    -2,\\n    -1,\\n    0,\\n    1,\\n    2,\\n    3,\\n    4,\\n    5,\\n]:\\n    print(\\n        func_with_bias(\\n            np.array([log_sigma2]),\\n            X1,\\n            y1,\\n        )\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for log_sigma2 in [\n",
    "    -4,\n",
    "    -3,\n",
    "    -2,\n",
    "    -1,\n",
    "    0,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    4,\n",
    "    5,\n",
    "]:\n",
    "    print(\n",
    "        func_with_bias(\n",
    "            np.array([log_sigma2]),\n",
    "            X1,\n",
    "            y1,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3620fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.81102697e-22])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"1/np.exp(res.x)\";\n",
       "                var nbb_formatted_code = \"1 / np.exp(res.x)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1 / np.exp(res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f9f6a8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 329.1250092965352\n",
       "        x: [ 4.932e+01]\n",
       "      nit: 3\n",
       "      jac: [ 0.000e+00]\n",
       "     nfev: 6\n",
       "     njev: 6\n",
       " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 127;\n",
       "                var nbb_unformatted_code = \"res\";\n",
       "                var nbb_formatted_code = \"res\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "380eb6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17095.442744711374"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 130;\n",
       "                var nbb_unformatted_code = \"loss(np.array([1.0] * 21), preprocessor.fit_transform(X), y, np.array([2.0] * 21))\";\n",
       "                var nbb_formatted_code = \"loss(np.array([1.0] * 21), preprocessor.fit_transform(X), y, np.array([2.0] * 21))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss(np.array([1.0] * 21), preprocessor.fit_transform(X), y, np.array([2.0] * 21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ea00ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.00532150e-01, 0.00000000e+00, 0.00000000e+00, 1.23977661e-04,\n",
       "        4.08172607e-04, 0.00000000e+00, 0.00000000e+00, 5.32150269e-04,\n",
       "        0.00000000e+00, 4.57763672e-05, 0.00000000e+00, 4.86373901e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 7.62939453e-04, 4.86373901e-04,\n",
       "        1.06430054e-03],\n",
       "       [0.00000000e+00, 5.05719185e-01, 0.00000000e+00, 4.68254089e-04,\n",
       "        5.24997711e-03, 9.55581665e-04, 0.00000000e+00, 4.76360321e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 8.10623169e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.90856171e-03, 6.50882721e-03, 4.06169891e-03,\n",
       "        7.76195526e-03],\n",
       "       [0.00000000e+00, 0.00000000e+00, 5.09937286e-01, 4.88662720e-03,\n",
       "        5.05065918e-03, 6.29043579e-03, 1.90734863e-05, 3.62777710e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.52587891e-05, 0.00000000e+00, 9.57489014e-04,\n",
       "        0.00000000e+00, 8.96453857e-03, 1.07955933e-02, 3.83377075e-03,\n",
       "        1.11389160e-02],\n",
       "       [1.23977661e-04, 4.69207764e-04, 4.88662720e-03, 5.05477905e-01,\n",
       "        0.00000000e+00, 1.94549561e-03, 0.00000000e+00, 3.53145599e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.23977661e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.71661377e-05, 9.56535339e-04,\n",
       "        0.00000000e+00, 4.38213348e-03, 9.17148590e-03, 3.40652466e-03,\n",
       "        6.51168823e-03],\n",
       "       [4.11987305e-04, 5.25283813e-03, 5.05065918e-03, 0.00000000e+00,\n",
       "        5.10711670e-01, 5.30242920e-03, 2.28881836e-05, 5.39398193e-03,\n",
       "        0.00000000e+00, 4.57763672e-05, 0.00000000e+00, 3.66210938e-04,\n",
       "        0.00000000e+00, 1.52587891e-05, 8.01086426e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 9.49096680e-03, 8.90350342e-03, 4.98199463e-03,\n",
       "        1.34582520e-02],\n",
       "       [0.00000000e+00, 9.55581665e-04, 6.28852844e-03, 1.94549561e-03,\n",
       "        5.29861450e-03, 5.07244110e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 7.24411011e-03, 4.97627258e-03, 1.77860260e-03,\n",
       "        9.10949707e-03],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.90734863e-05, 0.00000000e+00,\n",
       "        1.90734863e-05, 0.00000000e+00, 5.00019073e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.90734863e-05, 4.38690186e-05, 7.62939453e-05,\n",
       "        1.90734863e-05],\n",
       "       [5.34057617e-04, 4.76074219e-03, 3.62396240e-03, 3.53240967e-03,\n",
       "        5.38635254e-03, 0.00000000e+00, 0.00000000e+00, 5.08922577e-01,\n",
       "        0.00000000e+00, 4.57763672e-05, 0.00000000e+00, 4.88281250e-04,\n",
       "        0.00000000e+00, 1.52587891e-05, 8.08715820e-04, 9.53674316e-04,\n",
       "        0.00000000e+00, 6.60705566e-03, 1.30462646e-02, 6.52694702e-03,\n",
       "        1.08337402e-02],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.00000000e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [4.54187393e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.54187393e-05, 0.00000000e+00, 0.00000000e+00, 4.54187393e-05,\n",
       "        0.00000000e+00, 5.00045419e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.81555748e-04, 0.00000000e+00,\n",
       "        9.08374786e-05],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.00000000e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.19209290e-07, 0.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [4.86373901e-04, 0.00000000e+00, 0.00000000e+00, 1.23262405e-04,\n",
       "        3.63111496e-04, 0.00000000e+00, 0.00000000e+00, 4.86373901e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.00486374e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.80787659e-04, 4.86373901e-04,\n",
       "        9.72986221e-04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.00000000e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.66893005e-05, 0.00000000e+00,\n",
       "        1.66893005e-05, 0.00000000e+00, 0.00000000e+00, 1.66893005e-05,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 5.00016689e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00135803e-04, 0.00000000e+00,\n",
       "        1.66893005e-05],\n",
       "       [0.00000000e+00, 8.10503960e-04, 0.00000000e+00, 1.66893005e-05,\n",
       "        7.93874264e-04, 0.00000000e+00, 0.00000000e+00, 8.10503960e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.00810504e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.44267082e-03, 1.16252899e-03,\n",
       "        8.10503960e-04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 9.55611467e-04, 9.55611467e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.55611467e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.00955611e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.00203061e-03, 4.53889370e-05,\n",
       "        9.55611467e-04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.00000000e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [0.00000000e+00, 4.90951538e-03, 8.96453857e-03, 4.38308716e-03,\n",
       "        9.49096680e-03, 7.24792480e-03, 1.90734863e-05, 6.60705566e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 5.13874054e-01, 1.37634277e-02, 6.69097900e-03,\n",
       "        1.71203613e-02],\n",
       "       [9.76562500e-04, 6.59179688e-03, 1.09863281e-02, 9.27734375e-03,\n",
       "        8.78906250e-03, 4.88281250e-03, 0.00000000e+00, 1.31835938e-02,\n",
       "        0.00000000e+00, 2.44140625e-04, 0.00000000e+00, 4.88281250e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.46484375e-03, 1.95312500e-03,\n",
       "        0.00000000e+00, 1.36718750e-02, 5.32714844e-01, 1.02539062e-02,\n",
       "        2.17285156e-02],\n",
       "       [4.84466553e-04, 4.06265259e-03, 3.83377075e-03, 3.40652466e-03,\n",
       "        4.97436523e-03, 1.77764893e-03, 7.62939453e-05, 6.52694702e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.84466553e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.16348267e-03, 4.57763672e-05,\n",
       "        0.00000000e+00, 6.69097900e-03, 1.00784302e-02, 5.12523651e-01,\n",
       "        9.38415527e-03],\n",
       "       [1.06430054e-03, 7.76290894e-03, 1.11351013e-02, 6.50978088e-03,\n",
       "        1.34487152e-02, 9.10949707e-03, 1.90734863e-05, 1.08318329e-02,\n",
       "        0.00000000e+00, 8.96453857e-05, 0.00000000e+00, 9.72747803e-04,\n",
       "        0.00000000e+00, 1.52587891e-05, 8.08715820e-04, 9.55581665e-04,\n",
       "        0.00000000e+00, 1.71165466e-02, 2.17056274e-02, 9.38034058e-03,\n",
       "        5.27763367e-01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"approx_fprime(\\n    np.array([1.0] * 21),\\n    jac,\\n    1.4901161193847656e-08,\\n    *(preprocessor.fit_transform(X), y, np.array([2.0] * 21)),\\n)\";\n",
       "                var nbb_formatted_code = \"approx_fprime(\\n    np.array([1.0] * 21),\\n    jac,\\n    1.4901161193847656e-08,\\n    *(preprocessor.fit_transform(X), y, np.array([2.0] * 21)),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "approx_fprime(\n",
    "    np.array([1.0] * 21),\n",
    "    jac,\n",
    "    1.4901161193847656e-08,\n",
    "    *(preprocessor.fit_transform(X), y, np.array([2.0] * 21)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c6074a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"r = 1\\nbeta = np.array([1.0] * 21)\\nm = np.array([0.0] * 21)\\nq = 1/np.array([2.0] * 21)\\n\\nweights = np.ones(y.shape)\\nweights[y == 0] = 1 / r\\n\\nlinear_pred = np.dot(preprocessor.fit_transform(X), beta)\\ny_pred = BayesianLogisticRegression().link._inv_link(linear_pred)\\n\\nhess = np.diag(q) + np.matmul(\\n    np.matmul(\\n        preprocessor.fit_transform(X).T.to_numpy(),\\n        np.diag(np.multiply(weights, np.multiply(y_pred, 1 - y_pred))),\\n    ),\\n    preprocessor.fit_transform(X).to_numpy(),\\n)\";\n",
       "                var nbb_formatted_code = \"r = 1\\nbeta = np.array([1.0] * 21)\\nm = np.array([0.0] * 21)\\nq = 1 / np.array([2.0] * 21)\\n\\nweights = np.ones(y.shape)\\nweights[y == 0] = 1 / r\\n\\nlinear_pred = np.dot(preprocessor.fit_transform(X), beta)\\ny_pred = BayesianLogisticRegression().link._inv_link(linear_pred)\\n\\nhess = np.diag(q) + np.matmul(\\n    np.matmul(\\n        preprocessor.fit_transform(X).T.to_numpy(),\\n        np.diag(np.multiply(weights, np.multiply(y_pred, 1 - y_pred))),\\n    ),\\n    preprocessor.fit_transform(X).to_numpy(),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = 1\n",
    "beta = np.array([1.0] * 21)\n",
    "m = np.array([0.0] * 21)\n",
    "q = 1 / np.array([2.0] * 21)\n",
    "\n",
    "weights = np.ones(y.shape)\n",
    "weights[y == 0] = 1 / r\n",
    "\n",
    "linear_pred = np.dot(preprocessor.fit_transform(X), beta)\n",
    "y_pred = BayesianLogisticRegression().link._inv_link(linear_pred)\n",
    "\n",
    "hess = np.diag(q) + np.matmul(\n",
    "    np.matmul(\n",
    "        preprocessor.fit_transform(X).T.to_numpy(),\n",
    "        np.diag(np.multiply(weights, np.multiply(y_pred, 1 - y_pred))),\n",
    "    ),\n",
    "    preprocessor.fit_transform(X).to_numpy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abef22ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.00531936e-01, 0.00000000e+00, 0.00000000e+00, 1.23386632e-04,\n",
       "        4.08549642e-04, 1.39942169e-09, 0.00000000e+00, 5.31934874e-04,\n",
       "        0.00000000e+00, 4.53958078e-05, 2.12966051e-08, 4.86518289e-04,\n",
       "        8.30318036e-10, 3.97397670e-11, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.03952402e-11, 7.62715736e-04, 4.86534540e-04,\n",
       "        1.06386289e-03],\n",
       "       [0.00000000e+00, 5.05719221e-01, 0.00000000e+00, 4.68690204e-04,\n",
       "        5.25053032e-03, 9.55623353e-04, 3.99680289e-15, 4.76359717e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.87960758e-12, 3.68594044e-14, 8.10555835e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.90866468e-03, 6.50974333e-03, 4.06259720e-03,\n",
       "        7.76258607e-03],\n",
       "       [0.00000000e+00, 0.00000000e+00, 5.09934095e-01, 4.88596690e-03,\n",
       "        5.04812852e-03, 6.28940733e-03, 1.91256391e-05, 3.62556246e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.67011429e-05, 1.02875708e-10, 9.55616988e-04,\n",
       "        0.00000000e+00, 8.96177719e-03, 1.07949735e-02, 3.83242776e-03,\n",
       "        1.11363759e-02],\n",
       "       [1.23386632e-04, 4.68690204e-04, 4.88596690e-03, 5.05478044e-01,\n",
       "        0.00000000e+00, 1.94625626e-03, 1.01257133e-08, 3.53177736e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.06558358e-09, 1.23379735e-04,\n",
       "        7.88604514e-10, 3.96831457e-11, 1.67011436e-05, 9.55616988e-04,\n",
       "        0.00000000e+00, 4.38233898e-03, 9.17135383e-03, 3.40562015e-03,\n",
       "        6.51163716e-03],\n",
       "       [4.08549642e-04, 5.25053032e-03, 5.04812852e-03, 0.00000000e+00,\n",
       "        5.10707208e-01, 5.29877583e-03, 1.91155134e-05, 5.38931714e-03,\n",
       "        0.00000000e+00, 4.53958078e-05, 1.52310215e-08, 3.63138554e-04,\n",
       "        4.35931291e-11, 1.67011430e-05, 7.93854794e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 9.48810291e-03, 8.89607869e-03, 4.97593935e-03,\n",
       "        1.34511877e-02],\n",
       "       [1.39942169e-09, 9.55623353e-04, 6.28940733e-03, 1.94625626e-03,\n",
       "        5.29877583e-03, 5.07245032e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 8.04485811e-10, 5.88289195e-10,\n",
       "        3.29736238e-12, 9.52571355e-14, 2.22044605e-16, 0.00000000e+00,\n",
       "        0.00000000e+00, 7.24503069e-03, 4.97701225e-03, 1.77953626e-03,\n",
       "        9.11045725e-03],\n",
       "       [0.00000000e+00, 3.99680289e-15, 1.91256391e-05, 1.01257133e-08,\n",
       "        1.91155134e-05, 0.00000000e+00, 5.00019126e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 2.22044605e-15, 2.22044605e-15, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.91256391e-05, 4.37221281e-05, 7.64615865e-05,\n",
       "        1.91153966e-05],\n",
       "       [5.31934874e-04, 4.76359717e-03, 3.62556246e-03, 3.53177736e-03,\n",
       "        5.38931714e-03, 0.00000000e+00, 0.00000000e+00, 5.08921094e-01,\n",
       "        0.00000000e+00, 4.53958078e-05, 2.04921193e-08, 4.86517700e-04,\n",
       "        8.28900281e-10, 1.67011826e-05, 8.10555938e-04, 9.55616988e-04,\n",
       "        0.00000000e+00, 6.60628556e-03, 1.30466981e-02, 6.52556165e-03,\n",
       "        1.08332522e-02],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.00000000e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [4.53958078e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.53958078e-05, 0.00000000e+00, 0.00000000e+00, 4.53958078e-05,\n",
       "        0.00000000e+00, 5.00045396e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.81583232e-04, 0.00000000e+00,\n",
       "        9.07916155e-05],\n",
       "       [2.12966051e-08, 0.00000000e+00, 0.00000000e+00, 6.06558358e-09,\n",
       "        1.52310215e-08, 8.04485811e-10, 0.00000000e+00, 2.04921193e-08,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.00000021e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.61753451e-07, 1.63157554e-08,\n",
       "        3.48082449e-08],\n",
       "       [4.86518289e-04, 0.00000000e+00, 0.00000000e+00, 1.23379735e-04,\n",
       "        3.63138554e-04, 5.88289195e-10, 0.00000000e+00, 4.86517700e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.00486518e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.80856252e-04, 4.86518186e-04,\n",
       "        9.73035602e-04],\n",
       "       [8.30318036e-10, 1.87960758e-12, 0.00000000e+00, 7.88604514e-10,\n",
       "        4.35931291e-11, 3.29736238e-12, 0.00000000e+00, 8.28900281e-10,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.00000001e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.35883917e-08, 3.84439147e-11,\n",
       "        7.91832599e-10],\n",
       "       [3.97397670e-11, 3.68594044e-14, 1.67011429e-05, 3.96831457e-11,\n",
       "        1.67011430e-05, 9.52571355e-14, 2.22044605e-15, 1.67011826e-05,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 5.00016701e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00207582e-04, 1.06137321e-13,\n",
       "        1.67012203e-05],\n",
       "       [0.00000000e+00, 8.10555835e-04, 1.02875708e-10, 1.67011436e-05,\n",
       "        7.93854794e-04, 2.22044605e-16, 2.22044605e-15, 8.10555938e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.00810556e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.44265761e-03, 1.16249465e-03,\n",
       "        8.10555834e-04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 9.55616988e-04, 9.55616988e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.55616988e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.00955617e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.00202559e-03, 4.53958077e-05,\n",
       "        9.55616988e-04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.00000000e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [1.03952402e-11, 4.90866468e-03, 8.96177719e-03, 4.38233898e-03,\n",
       "        9.48810291e-03, 7.24503069e-03, 1.91256391e-05, 6.60628556e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 5.13870442e-01, 1.37598269e-02, 6.68713450e-03,\n",
       "        1.71160880e-02],\n",
       "       [7.62715736e-04, 6.50974333e-03, 1.07949735e-02, 9.17135383e-03,\n",
       "        8.89607869e-03, 4.97701225e-03, 4.37221281e-05, 1.30466981e-02,\n",
       "        0.00000000e+00, 1.81583232e-04, 2.61753451e-07, 5.80856252e-04,\n",
       "        1.35883917e-08, 1.00207582e-04, 1.44265761e-03, 2.00202559e-03,\n",
       "        0.00000000e+00, 1.37598269e-02, 5.32815243e-01, 1.00782545e-02,\n",
       "        2.17071454e-02],\n",
       "       [4.86534540e-04, 4.06259720e-03, 3.83242776e-03, 3.40562015e-03,\n",
       "        4.97593935e-03, 1.77953626e-03, 7.64615865e-05, 6.52556165e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.63157554e-08, 4.86518186e-04,\n",
       "        3.84439147e-11, 1.06137321e-13, 1.16249465e-03, 4.53958077e-05,\n",
       "        0.00000000e+00, 6.68713450e-03, 1.00782545e-02, 5.12521273e-01,\n",
       "        9.38123843e-03],\n",
       "       [1.06386289e-03, 7.76258607e-03, 1.11363759e-02, 6.51163716e-03,\n",
       "        1.34511877e-02, 9.11045725e-03, 1.91153966e-05, 1.08332522e-02,\n",
       "        0.00000000e+00, 9.07916155e-05, 3.48082449e-08, 9.73035602e-04,\n",
       "        7.91832599e-10, 1.67012203e-05, 8.10555834e-04, 9.55616988e-04,\n",
       "        0.00000000e+00, 1.71160880e-02, 2.17071454e-02, 9.38123843e-03,\n",
       "        5.27765661e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"hess\";\n",
       "                var nbb_formatted_code = \"hess\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5ce16f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cr_model_research",
   "language": "python",
   "name": "cr_model_research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
